{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de objeto pandas dataframe\n",
    "patients_df=pd.read_csv('https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación variables binarias\n",
    "patients_df.replace({'sex':{'male':0,'female':1}}, inplace=True)\n",
    "patients_df.replace({'smoker':{'yes':1,'no':0}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función get dummies convierte un DataFrame de columnas categoricas a uno con variables dummy variables\n",
    "region_dummies_df=pd.get_dummies(patients_df[['region']])\n",
    "region_dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos join entre los 2 dataframes para reconstruir el dataset\n",
    "patients_df = patients_df.join(region_dummies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso 70% para entrenamiento (random split)\n",
    "train_df= patients_df.sample(frac=0.7,random_state=200)\n",
    "rest_df = patients_df.drop(train_df.index)\n",
    "# Uso 15% para validacion y 15% para test\n",
    "val_df=rest_df.sample(frac=0.5,random_state=200)\n",
    "test_df=rest_df.drop(val_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model(X, Y, lr=0.00001, epochs=100, patience=10): \n",
    "    \"\"\"Implementación de la función de entrenamiento por descendo de gracdiente\n",
    "\n",
    "    Args:\n",
    "        X (np array): vector de características nxm\n",
    "        Y (np array): vector de variable objetivo\n",
    "    \"\"\"\n",
    "\n",
    "    #Generacion de los thetas aleatorios\n",
    "    n, m = X.shape\n",
    "    theta = np.random.rand(m+1,1)\n",
    "    #Se agrega la dimension\n",
    "    X_c = np.hstack((np.ones((n,1)),X))\n",
    "    loss_v = []\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        Y_est = X_c.dot(theta)\n",
    "        #Calcular la perdidad\n",
    "        loss = np.sum(np.power(Y_est-Y,2))/(2.*n)\n",
    "        loss_v.append(loss)\n",
    "        #calculo gradientes\n",
    "        gradientes = (-1/n)*(X_c.T.dot((Y - X_c.dot(theta))))\n",
    "        #actualizar\n",
    "        theta = theta - lr*gradientes\n",
    "\n",
    "        # Esto se agrega para parar el entrenamiento en caso de que la perdida no disminuya por mas del valor del parametro patience\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_theta = np.copy(theta)\n",
    "            epochs_stall = 0\n",
    "        else:\n",
    "            epochs_stall+=1\n",
    "        if epochs_stall>=patience:\n",
    "            print('La funcion de perdida no ha disminuido, parando despues de {} epocas. el error es: {}'.format(epoch, loss))\n",
    "            break\n",
    "        print('Epoch: {} Loss: {:.4e}'.format(epoch, loss))\n",
    "\n",
    "    print('El error fue: {:.4e}'.format(loss))\n",
    "    return best_theta, loss_v\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
